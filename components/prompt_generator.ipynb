{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototype Code : Prompt Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Generator + LLM\n",
    "\n",
    "# CONTEXT\n",
    "template = \"\"\"\n",
    "You are a quality assurance expert that generates functional test cases for websites. You take in a UI element and you generate a functional test case.\n",
    "\n",
    "Here is the UI element (some elements have a link attached to them): {question}\n",
    "ONLY output in the following format: \n",
    "\"Objective\"~\"Preconditions\"~\"Test Steps\"~\"Expected Result\"\n",
    "\n",
    "DO NOT output any other text. DO NOT output 'Here are the test cases...', your output should be like the example output below.\n",
    "\n",
    "Example Input:\n",
    "Link Element: Home with URL : https://bicol-u.edu.ph/\n",
    "Link Element: Academics with URL : https://bicol-u.edu.ph/#\n",
    "...\n",
    "\n",
    "Example Output:\n",
    "\"Verify the functionality of the Link Element 'Home'\"~\"The user is on the webpage 'https://bicol-u.edu.ph/'\"~\"'1. User navigates to the webpage \\'https://bicol-u.edu.ph/\\'' '2. Click on Link Element \\'Home\\'' '3. Verify if the webpage opens in a new tab/window.'\"~\"Webpage 'https://bicol-u.edu.ph/' should open in a new tab/window.\"\n",
    "\"Verify the functionality of the Link Element 'Academics'\"~\"The user is on the webpage 'https://bicol-u.edu.ph/'\"~\"'1. User navigates to the webpage \\'https://bicol-u.edu.ph/\\'' '2. Click on Link Element \\'Academics\\'' '3. Verify if the link url changes to \\'https://bicol-u.edu.ph/#\\'' '4. Verify if a dropdown below \\'Academics\\' is visible'\"~\"A dropdown should show below 'Academics', but the webpage does not change\"\n",
    "...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load Model Chain\n",
    "def load_model_chain(template : str =  template, model_str : str = \"llama3.1\"):\n",
    "    # Prompt\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    # Model\n",
    "    model = OllamaLLM(model=model_str)\n",
    "    # Chain\n",
    "    chain = prompt | model\n",
    "    return chain\n",
    "\n",
    "# Create Test Case Data\n",
    "def create_test_cases(data, chain, model_str : str = \"llama3.1\" , template : str = template, batch_size : int = 10):\n",
    "    \n",
    "    return_data = []\n",
    "    \n",
    "    for sub_data in data:\n",
    "        element_test_cases = []\n",
    "        i = 0\n",
    "        j = 0\n",
    "        print(f\"Batch Number: {ceil(len(sub_data)/batch_size)}\")\n",
    "        while (j<ceil(len(sub_data)/batch_size)):\n",
    "            print(f\"[{j}] Batch {str(len(sub_data[i:i+batch_size]))}\")\n",
    "            appending = []\n",
    "            for dat in sub_data[i:i+batch_size]:\n",
    "                appending.append(chain.invoke({\"question\": str(dat)}))\n",
    "            element_test_cases.append(appending)\n",
    "            i+=batch_size\n",
    "            j+=1\n",
    "            prompt = ChatPromptTemplate.from_template(template)\n",
    "            model = OllamaLLM(model=model_str)\n",
    "            chain = prompt | model\n",
    "        return_data.append(element_test_cases)\n",
    "    return return_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 1 : Dissection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt Generator + LLM\n",
    "\n",
    "# TODO : Streamline Process (make it easier to read)\n",
    "\n",
    "# CONTEXT\n",
    "template = \"\"\"\n",
    "You are a quality assurance expert that generates functional test cases for websites. You take in a UI element and you generate a functional test case.\n",
    "\n",
    "Here is the UI element (some elements have a link attached to them): {question}\n",
    "ONLY output in the following format: \n",
    "\"Objective\"~\"Preconditions\"~\"Test Steps\"~\"Expected Result\"\n",
    "\n",
    "DO NOT output any other text. DO NOT output 'Here are the test cases...', your output should be like the example output below.\n",
    "\n",
    "Example Input:\n",
    "Link Element: Home with URL : https://bicol-u.edu.ph/\n",
    "Link Element: Academics with URL : https://bicol-u.edu.ph/#\n",
    "...\n",
    "\n",
    "Example Output:\n",
    "\"Verify the functionality of the Link Element 'Home'\"~\"The user is on the webpage 'https://bicol-u.edu.ph/'\"~\"'1. User navigates to the webpage \\'https://bicol-u.edu.ph/\\'' '2. Click on Link Element \\'Home\\'' '3. Verify if the webpage opens in a new tab/window.'\"~\"Webpage 'https://bicol-u.edu.ph/' should open in a new tab/window.\"\n",
    "\"Verify the functionality of the Link Element 'Academics'\"~\"The user is on the webpage 'https://bicol-u.edu.ph/'\"~\"'1. User navigates to the webpage \\'https://bicol-u.edu.ph/\\'' '2. Click on Link Element \\'Academics\\'' '3. Verify if the link url changes to \\'https://bicol-u.edu.ph/#\\'' '4. Verify if a dropdown below \\'Academics\\' is visible'\"~\"A dropdown should show below 'Academics', but the webpage does not change\"\n",
    "...\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Load Model Chain\n",
    "def load_model_chain(template : str =  template, model_str : str = \"llama3.1\"):\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    model = OllamaLLM(model=model_str)\n",
    "    chain = prompt | model\n",
    "    return chain\n",
    "\n",
    "# Create Test Case Data\n",
    "def create_test_cases(data, model_str : str = \"llama3.1\" , template : str = template, batch_size : int = 10):\n",
    "    \n",
    "    # Load LLM Chain\n",
    "    chain = load_model_chain(template, model_str)\n",
    "\n",
    "    # Return Data\n",
    "    return_data = []\n",
    "    \n",
    "    # # Sub Data is a set of elements in a particular element type (aka button_list from the main data_list)\n",
    "    # # CONSIDER TODO : Don't compile the elements as a list in list (scraper)\n",
    "    # for sub_data in data:\n",
    "\n",
    "    #     element_test_cases = []\n",
    "\n",
    "    #     appending = []\n",
    "        \n",
    "    #     for dat in sub_data: # Can be read as button in button_list_data\n",
    "    #         appending.append(chain.invoke({\"question\": str(dat)})) # Prompt Generator : Append UI Element to Prompt Template\n",
    "    #     element_test_cases.append(appending)\n",
    "            \n",
    "    #     # LLM Reset To Free Up Context\n",
    "    #     chain = load_model_chain(template, model_str)\n",
    "\n",
    "    #     return_data.append(element_test_cases)\n",
    "\n",
    "    #     \"\"\"\n",
    "    #     How the current structure looks like:\n",
    "    #         return_data\n",
    "    #             element_test_cases[0] # element set\n",
    "    #                 appending # \n",
    "    #                     llm output[0]: \"Verify the functionality of the Link Element 'Home'\"~\"The user is on the webpage 'https://bicol-u.edu.ph/'\"~\"'1. User navigates to the webpage \\'https://bicol-u.edu.ph/\\'' '2. Click on Link Element \\'Home\\'' '3. Verify if the webpage opens in a new tab/window.'\"~\"Webpage 'https://bicol-u.edu.ph/' should open in a new tab/window.\"\n",
    "    #                     llm output[1]: \n",
    "    #             element_test_cases[1]\n",
    "    #     \"\"\"\n",
    "\n",
    "    # Suggestion:\n",
    "    for sub_data in data:\n",
    "        for dat in sub_data:\n",
    "            return_data.append(chain.invoke({\"question\": str(dat)}))\n",
    "            # LLM Reset To Free Up Context\n",
    "            chain = load_model_chain(template, model_str)\n",
    "\n",
    "    return return_data\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
